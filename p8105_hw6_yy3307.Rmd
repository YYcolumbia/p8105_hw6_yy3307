---
title: "p8105_hw6_yy3307"
output: github_document
date: "2022-11-29"
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
```

## Problem 2

First we need to import and clean the `homicide` dataset. Then I'm going to create a `city_state` variable as combination of `city` and `state`, with a binary variable indicating whether the homicide is solved. `victim_age` will be `mutate` as numeric expression. Dallas, TX; Phoenix, AZ; Kansas City, MO; Tulsa, AL are being omitted and we only focus our analysis on those for whom `victim_race` is `white` or `black`.

```{r, warning = FALSE}
homicide_raw = 
  read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    solve_binary = as.numeric(
      ifelse(disposition == "Closed by arrest", 1, 0)
    ),
    victim_age = as.numeric(victim_age)
  ) %>% 
  filter(
    city_state != "Dallas, TX", 
    city_state != "Phoenix, AZ", 
    city_state != "Kansas City, MO", 
    city_state != "Tulsa, AL"
  ) %>% 
  filter(victim_race %in% c("White", "Black"))
```

Then I'm going to use the `glm` function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors for city of Baltimore, MD. After applying `broom::tidy` to it, we need to calculate the estimate and confidence interval.

```{r}
baltimore_logistic =
  homicide_raw %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solve_binary ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_upper = exp(estimate + 1.96 * std.error),
    CI_lower = exp(estimate - 1.96 * std.error)
  ) %>% 
  select(term, OR, CI_lower, CI_upper) %>% 
  knitr::kable(digits = 3)

baltimore_logistic
```

Now we are going to run the same process for each cities and extract corresponding odds ratio and CI, but this time we will do it with a tidy pipeline using `nest`, `unnest`, and `map`.

```{r}
cities_logistic =
  homicide_raw %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(data, ~glm(solve_binary ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
    results = map(models, broom::tidy)) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    OR = exp(estimate),
    CI_upper = exp(estimate + 1.96 * std.error),
    CI_lower = exp(estimate - 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, CI_lower, CI_upper)

cities_logistic
```

The last step is to plot the estimated ORs and CIs for each city. Confidence intervals are shown as `errorbar` in the plot.

```{r}
city_plot = 
  cities_logistic %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  labs(
    title = "City OR Solving Homicides Comparing Male Victims to Female Victims",
    x = "City State",
    y = "Odds Ratio"
  ) +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.7, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

city_plot
```

_**Comments:**_

From the plot we can analyze that the range for City OR Solving Homicides Comparing Male Victims to Female Victims is from about 0.25 to 1.75. Generally odds ratio for most of the cities falls below 1. New York, NY has the lowest odds ratio and Albuquerque, NM has the highest odds ratio. We can also tell that the confidence interval for each city does not follows a specific increasing trend, some cities may have low OR with long CI and some may have high OR with shortter CI.

## Problem 3

The first step is to load and clean the data for regression analysis, we need to convert numeric to factor and check for missing data. I would use `as.factor` to change the numerics into factors.

```{r, message = FALSE}
birthweight_raw =
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) %>% 
  select(bwt, everything())

sum(is.na(birthweight_raw))

birthweight_raw
```

From the counting `NA`s result shown above we can conclude that there is actually no missing values in this dataset. However, we can observe that almost for all data in `parity`, `pnumlbw`, `pnumgsa` are 0 and these variables are not factor variables. We might consider if there was some missing or input error in these variables with a large sample size even these events are rare to happen.

Before making a regression model for birthweight, we need to decide which variables are necessay and important for model hypothesis testing. We can first fit regression using all predictors and select variables using `backward` elimination to help us make valid selections.

```{r}
mult_fit = 
  lm(bwt ~., data = birthweight_raw)

step(mult_fit, direction = 'backward')
```

From the result shown above, I'm going to select `bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken` as hypothesis testing variables and propose a regression model for birthweight based on these variables.

```{r}
model_final =
  lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_raw)

model_final %>% 
  broom::tidy()
```

After getting the fitted model for birthweight, we can make a plot of model residuals against fitted values. First, we can use `add_residuals` and `add_predictions` to find these values, then we just need to express them as `grom_point`.

```{r}
birthweight_raw %>% 
  add_residuals(model_final) %>% 
  add_predictions(model_final) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  labs(
    title = "Model Residuals Against Fitted Values",
    x = "Fitted value",
    y = "Residuals"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

Compare the model to two others using cross-validation:

One using length at birth and gestational age as predictors (main effects only)

One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

Firstly, we need to fit the model for these variables under two conditions.

```{r}
comp1_model = 
  lm(bwt ~ blength + gaweeks, data = birthweight_raw) %>% 
  broom::tidy()

comp2_model = 
  lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthweight_raw) %>% 
  broom::tidy()
```

Then we can use cross-validation to compare the new model with our previous fitted against residual model.

```{r}
cv_df = 
  crossv_mc(birthweight_raw, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    fit_origin = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_raw)),
    fit_comp1 = map(train, ~lm(bwt ~ blength + gaweeks, data = birthweight_raw)),
    fit_comp2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthweight_raw))
  ) %>% 
  mutate(
    rmse_origin = map2_dbl(fit_origin, test, ~rmse(model = .x, data = .y)),
    rmse_comp1 = map2_dbl(fit_comp1, test, ~rmse(model = .x, data = .y)),
    rmse_comp2 = map2_dbl(fit_comp2, test, ~rmse(model = .x, data = .y))
  )
```

The plot below shows the distribution of RMSE values for each model.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Model Comparison",
    x = "Models",
    y = "RMSE"
  ) +
  theme(plot.title = element_text(hjust = .5))
```

From the violin plot shown above, we can see that our origin model has the lowest RMSE, the second comparison model using head circumference, length, sex, and all interactions as predictors has medium RMSE, and first comparison model using length at birth and gestational age as predictors has highest RMSE. Also, the origin model has similar shape distribution as the second comparison model.